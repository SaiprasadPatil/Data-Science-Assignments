{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e135a2d-7927-4dad-89c7-9422d9e37021",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80e52e9-d6b7-41b6-aa0b-7e94104c7da0",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical method used to compare the means of three or more groups to determine if there are statistically significant differences between them. To use ANOVA effectively, certain assumptions must be met. These assumptions include:\n",
    "\n",
    "1. **Independence**: Observations within each group are independent of each other. This means that the value of one observation does not influence the value of another observation within the same group.\n",
    "\n",
    "2. **Normality**: The data within each group should be approximately normally distributed. This means that when you plot the data for each group, it should resemble a bell curve.\n",
    "\n",
    "3. **Homogeneity of variances (homoscedasticity)**: The variance of the data within each group should be approximately equal. In other words, the spread of the data points around the mean should be similar for all groups.\n",
    "\n",
    "Violations of these assumptions can impact the validity of ANOVA results:\n",
    "\n",
    "1. **Independence**: Violations occur when observations within groups are not independent. For example, in a repeated measures design where the same subjects are measured under different conditions, the observations within each group may be correlated. This violates the assumption of independence and can lead to inflated Type I error rates.\n",
    "\n",
    "2. **Normality**: Violations of normality can occur when the data within groups are not normally distributed. This can happen when the data are heavily skewed or have outliers. In such cases, the ANOVA results may be unreliable, especially if the sample sizes are small.\n",
    "\n",
    "3. **Homogeneity of variances**: Violations occur when the variances of the data within groups are not equal. This can lead to inaccurate p-values and confidence intervals. One common example is when one group has much larger variance than the others, leading to unequal spread of data points around the group means.\n",
    "\n",
    "When these assumptions are violated, alternative statistical tests or transformations of the data may be necessary to obtain valid results. For example, non-parametric tests like the Kruskal-Wallis test can be used instead of ANOVA when the assumption of normality is violated. Additionally, transforming the data using methods like logarithmic or square root transformations can sometimes help meet the assumptions of normality and homogeneity of variances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eed931-4a01-4d1e-8626-91e8c69e759c",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba0a889-2d94-4fd5-95d1-ace0ce27efb3",
   "metadata": {},
   "source": [
    "The three types of ANOVA are:\n",
    "\n",
    "1. **One-Way ANOVA**: One-Way ANOVA is used when you have one independent variable (factor) with three or more levels (groups), and you want to determine if there are statistically significant differences between the means of the groups. It is typically used in situations where you are comparing the means of multiple groups to see if there is a significant difference in a single dependent variable. For example, you might use a one-way ANOVA to compare the exam scores of students who studied with three different study methods (e.g., group A studied with flashcards, group B studied by summarizing notes, and group C studied by teaching the material to someone else).\n",
    "\n",
    "2. **Two-Way ANOVA**: Two-Way ANOVA is used when you have two independent variables (factors), and you want to determine if there are main effects of each factor as well as if there is an interaction effect between the two factors on the dependent variable. It is commonly used in experimental designs where there are two factors being manipulated simultaneously. For example, you might use a two-way ANOVA to analyze the effects of both diet (factor 1) and exercise (factor 2) on weight loss.\n",
    "\n",
    "3. **Repeated Measures ANOVA**: Repeated Measures ANOVA is used when you have a within-subjects design, meaning that the same subjects are measured under different conditions or at different time points. It is used to analyze changes in a dependent variable over time or in response to different treatments within the same subjects. For example, you might use a repeated measures ANOVA to analyze changes in participants' anxiety levels before and after receiving different types of therapy.\n",
    "\n",
    "Each type of ANOVA is suited to different experimental designs and research questions, so it's important to choose the appropriate type based on the specific characteristics of your study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa434b8-ec3e-4370-9db1-602580a14401",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce159f36-a51b-47f6-9bfa-e331002a3cdc",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the process of decomposing the total variance observed in a dataset into different components that are attributable to different sources or factors. Understanding this concept is crucial because it allows researchers to quantify and identify the sources of variation in their data, which in turn helps in making inferences about the factors that may be influencing the dependent variable.\n",
    "\n",
    "In ANOVA, the total variance observed in the data is partitioned into three main components:\n",
    "\n",
    "1. **Between-group variance (SSB)**: This component of variance represents the variation between the group means. It indicates how much the means of the different groups deviate from each other. In other words, it measures the extent to which the independent variable (or factors) explains the variation in the dependent variable.\n",
    "\n",
    "2. **Within-group variance (SSW)**: Also known as error variance, this component represents the variability within each group. It reflects the random variability or noise in the data that is not accounted for by the independent variable(s). Essentially, it measures the amount of unexplained variation within each group.\n",
    "\n",
    "3. **Total variance (SST)**: This is the overall variability observed in the entire dataset, regardless of group membership. It is the sum of the between-group and within-group variances.\n",
    "\n",
    "The importance of understanding the partitioning of variance in ANOVA lies in its ability to provide insights into the underlying structure of the data and the factors that influence the dependent variable. By quantifying the amount of variance attributed to different sources, researchers can assess the significance of the independent variable(s) and determine whether there are statistically significant differences between the group means. This information is essential for making informed interpretations and conclusions about the relationships between variables and for designing future experiments or interventions. Additionally, understanding the partitioning of variance facilitates comparisons between different models or experimental conditions and helps in identifying potential sources of error or variability that may need to be addressed in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1c44ec-04cd-46f4-bb9f-c91f5ed57bf8",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8799207f-3fa6-404c-9d01-e5a59490e417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 60.0\n",
      "Explained Sum of Squares (SSE): group\n",
      "A     9.0\n",
      "B    36.0\n",
      "C    81.0\n",
      "Name: value, dtype: float64\n",
      "Residual Sum of Squares (SSR): group\n",
      "A    51.0\n",
      "B    24.0\n",
      "C   -21.0\n",
      "Name: value, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84/1180412282.py:22: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  squared_deviations_explained = np.sum((group_means - grand_mean) ** 2 * len(data[data['group'] == group]) for group in data['group'].unique())\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "data = pd.DataFrame({\n",
    "    'group': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'value': [5, 7, 9, 8, 6, 10, 3, 2, 4]\n",
    "})\n",
    "\n",
    "# Fit one-way ANOVA model\n",
    "model = ols('value ~ group', data=data).fit()\n",
    "\n",
    "# Calculate total sum of squares (SST)\n",
    "grand_mean = data['value'].mean()\n",
    "squared_deviations_total = np.sum((data['value'] - grand_mean) ** 2)\n",
    "SST = squared_deviations_total\n",
    "\n",
    "# Calculate explained sum of squares (SSE)\n",
    "group_means = data.groupby('group')['value'].mean()\n",
    "squared_deviations_explained = np.sum((group_means - grand_mean) ** 2 * len(data[data['group'] == group]) for group in data['group'].unique())\n",
    "SSE = squared_deviations_explained\n",
    "\n",
    "# Calculate residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b546469-4759-4776-8e17-6b4e56f5413a",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e9e8d0c-76c0-4784-adec-f99aa01a70db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1772: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=9\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/regression/linear_model.py:1765: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/regression/linear_model.py:1765: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/regression/linear_model.py:1687: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  value   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Sun, 05 May 2024   Prob (F-statistic):                nan\n",
      "Time:                        05:13:38   Log-Likelihood:                 283.43\n",
      "No. Observations:                   9   AIC:                            -548.9\n",
      "Df Residuals:                       0   BIC:                            -547.1\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                    10.0000        inf          0        nan         nan         nan\n",
      "factor1[T.B]                  8.0000        inf          0        nan         nan         nan\n",
      "factor1[T.C]                 -2.0000        inf         -0        nan         nan         nan\n",
      "factor2[T.Y]                  5.0000        inf          0        nan         nan         nan\n",
      "factor2[T.Z]                  2.0000        inf          0        nan         nan         nan\n",
      "factor1[T.B]:factor2[T.Y]    -3.0000        inf         -0        nan         nan         nan\n",
      "factor1[T.C]:factor2[T.Y]    -4.0000        inf         -0        nan         nan         nan\n",
      "factor1[T.B]:factor2[T.Z]    -4.0000        inf         -0        nan         nan         nan\n",
      "factor1[T.C]:factor2[T.Z]     1.0000        inf          0        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                        0.309   Durbin-Watson:                   1.405\n",
      "Prob(Omnibus):                  0.857   Jarque-Bera (JB):                0.426\n",
      "Skew:                           0.224   Prob(JB):                        0.808\n",
      "Kurtosis:                       2.033   Cond. No.                         13.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'factor1[T.A]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'factor1[T.A]'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Extract main effects and interaction effect\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m main_effect_factor1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor1[T.B]\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfactor1[T.A]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     21\u001b[0m main_effect_factor2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor2[T.Y]\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m model\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor2[T.X]\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     22\u001b[0m interaction_effect \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor1[T.B]:factor2[T.Y]\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m model\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor1[T.A]:factor2[T.X]\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'factor1[T.A]'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "data = pd.DataFrame({\n",
    "    'factor1': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'factor2': ['X', 'Y', 'Z', 'X', 'Y', 'Z', 'X', 'Y', 'Z'],\n",
    "    'value': [10, 15, 12, 18, 20, 16, 8, 9, 11]\n",
    "})\n",
    "\n",
    "# Fit two-way ANOVA model\n",
    "model = ols('value ~ factor1 + factor2 + factor1:factor2', data=data).fit()\n",
    "\n",
    "# Print ANOVA table\n",
    "print(model.summary())\n",
    "\n",
    "# Extract main effects and interaction effect\n",
    "main_effect_factor1 = model.params['factor1[T.B]'] - model.params['factor1[T.A]']\n",
    "main_effect_factor2 = model.params['factor2[T.Y]'] - model.params['factor2[T.X]']\n",
    "interaction_effect = model.params['factor1[T.B]:factor2[T.Y]'] - model.params['factor1[T.A]:factor2[T.X]']\n",
    "\n",
    "print(\"Main Effect of Factor 1:\", main_effect_factor1)\n",
    "print(\"Main Effect of Factor 2:\", main_effect_factor2)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d056fa33-68a6-4ada-bc27-16eaeb55a95c",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9881bcf6-ad02-4351-a4d0-a599360967f2",
   "metadata": {},
   "source": [
    "In this scenario, you conducted a one-way ANOVA to compare the means of multiple groups, and you obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "\n",
    "Based on these results:\n",
    "\n",
    "1. **F-statistic**: The F-statistic measures the ratio of the variance between groups to the variance within groups. In this case, an F-statistic of 5.23 indicates that there is some degree of difference between the group means.\n",
    "\n",
    "2. **p-value**: The p-value associated with the F-statistic indicates the probability of observing the data if the null hypothesis (i.e., the assumption that there are no differences between the group means) is true. A p-value of 0.02 suggests that there is strong evidence against the null hypothesis.\n",
    "\n",
    "Therefore, with a p-value of 0.02, you would typically conclude that there are statistically significant differences between the groups.\n",
    "\n",
    "Interpretation:\n",
    "Since the p-value is less than the conventional significance level (e.g., 0.05), you would reject the null hypothesis and conclude that there are statistically significant differences between at least two of the groups. However, the one-way ANOVA test does not indicate which specific groups are different from each other. To determine which groups are different, you would typically conduct post-hoc tests, such as Tukey's HSD (Honestly Significant Difference) test or pairwise t-tests with appropriate adjustments for multiple comparisons.\n",
    "\n",
    "In summary, the results of the one-way ANOVA suggest that there are statistically significant differences between the groups, but further analyses are needed to identify which specific groups differ from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2af09e-a39a-4096-848f-83efbe67b583",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b062342-165d-4bf4-89f4-41d684823eb7",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA requires careful consideration, as missing data can potentially bias the results and reduce statistical power. There are several methods to handle missing data in repeated measures ANOVA:\n",
    "\n",
    "1. **Complete Case Analysis (CCA)**: This approach involves analyzing only the cases (participants) with complete data for all time points. While this method is straightforward, it may lead to reduced sample sizes and potentially biased results if the missing data are not completely random.\n",
    "\n",
    "2. **Mean Imputation**: Missing values are replaced with the mean of the available data for that variable. While mean imputation is simple to implement, it can artificially reduce variability and bias the results if the missing data are not missing completely at random.\n",
    "\n",
    "3. **Last Observation Carried Forward (LOCF)**: Missing values are replaced with the last observed value for that participant. This method assumes that the participant's response remains constant over time, which may not always be the case and can lead to biased estimates, especially if there is a trend in the data.\n",
    "\n",
    "4. **Linear Interpolation**: Missing values are replaced by values estimated from neighboring time points using linear interpolation. This method assumes a linear relationship between successive time points and may not accurately capture the true trajectory of the data, especially if the missingness is non-linear.\n",
    "\n",
    "5. **Multiple Imputation**: Missing values are imputed multiple times to create several complete datasets, and analyses are performed on each dataset. The results are then pooled to obtain overall estimates. Multiple imputation is considered one of the most robust methods for handling missing data, as it properly accounts for uncertainty due to missingness. However, it can be computationally intensive and requires assumptions about the missing data mechanism.\n",
    "\n",
    "The potential consequences of using different methods to handle missing data include biased estimates, inflated standard errors, reduced statistical power, and inaccurate conclusions. It's essential to carefully consider the assumptions underlying each method and the potential impact on the validity of the results. Additionally, sensitivity analyses or comparing results obtained using different imputation methods can help assess the robustness of the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910de2a-d088-47c3-bed9-2821cbc8da2f",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9894b9d3-0996-4b18-8bc3-c94ae54e55e4",
   "metadata": {},
   "source": [
    "Common post-hoc tests used after ANOVA include Tukey's Honestly Significant Difference (HSD) test, Bonferroni correction, Sidak correction, Duncan's Multiple Range Test, and Scheffé's Test. Here's when you might use each one:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD) Test**: This test is suitable when you have equal sample sizes and homogeneity of variances. It's commonly used when you want to compare all possible pairs of group means to determine which specific groups differ from each other while controlling the overall Type I error rate.\n",
    "\n",
    "2. **Bonferroni Correction**: Bonferroni correction is a conservative approach that adjusts the significance level for multiple comparisons to control the family-wise error rate. It's useful when you want to maintain an overall alpha level while testing multiple pairwise comparisons.\n",
    "\n",
    "3. **Sidak Correction**: Sidak correction is similar to Bonferroni correction but tends to be less conservative. It's suitable when you want to adjust the significance level for multiple comparisons while maintaining control over the family-wise error rate.\n",
    "\n",
    "4. **Duncan's Multiple Range Test**: Duncan's test compares all possible pairs of group means and identifies homogeneous subsets of means that do not differ significantly from each other. It's less conservative than Tukey's HSD test but assumes equal variances and may be less robust when sample sizes are unequal.\n",
    "\n",
    "5. **Scheffé's Test**: Scheffé's test is a conservative post-hoc test that controls the family-wise error rate for all possible comparisons among group means. It's robust to unequal sample sizes and variances but tends to be less powerful than other post-hoc tests.\n",
    "\n",
    "Here's an example situation where a post-hoc test might be necessary:\n",
    "\n",
    "Suppose you conducted an experiment to compare the effectiveness of three different teaching methods (A, B, and C) on student performance in a mathematics course. After conducting a one-way ANOVA, you found a statistically significant difference in mean test scores between the three teaching methods (p < 0.05). However, the ANOVA does not tell you which specific teaching methods are different from each other.\n",
    "\n",
    "In this scenario, you would need to perform post-hoc tests, such as Tukey's HSD test or Bonferroni correction, to determine pairwise differences between the teaching methods. This would help you identify which teaching methods lead to significantly different outcomes and provide more detailed insights for interpreting the results of your study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25724136-98fb-461c-8983-522d5daf5e9e",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af89add-fc75-4c05-8667-5b7f8234c9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 12.750574846127048\n",
      "p-value: 1.8181066222880367e-05\n",
      "The p-value is less than 0.05, indicating that there is a significant difference in mean weight loss between at least two of the diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Example data (weight loss in pounds)\n",
    "diet_A = [3.2, 4.5, 2.8, 3.9, 4.1, 2.5, 3.7, 4.0, 3.6, 3.8, 2.9, 4.2, 3.3, 4.4, 3.5, 2.7, 3.1, 4.6, 3.4, 2.6, 4.3, 3.0, 4.7, 2.4, 3.8]\n",
    "diet_B = [2.5, 3.6, 1.8, 2.9, 3.1, 1.5, 2.7, 3.0, 2.6, 2.8, 1.9, 3.2, 2.3, 3.4, 2.5, 1.7, 2.1, 3.6, 2.4, 1.6, 3.3, 2.0, 3.7, 1.4, 2.8]\n",
    "diet_C = [2.8, 3.9, 2.2, 3.3, 3.5, 2.0, 3.2, 3.5, 3.1, 3.4, 2.5, 3.6, 2.7, 3.8, 2.9, 2.1, 2.5, 3.9, 2.7, 1.9, 3.7, 2.4, 4.0, 1.8, 3.4]\n",
    "\n",
    "# Combine data\n",
    "data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "\n",
    "# Generate group labels\n",
    "labels = ['A'] * len(diet_A) + ['B'] * len(diet_B) + ['C'] * len(diet_C)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "F_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-statistic:\", F_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"The p-value is less than 0.05, indicating that there is a significant difference in mean weight loss between at least two of the diets.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than or equal to 0.05, indicating that there is no significant difference in mean weight loss between the diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce7b62c-f80a-4153-a163-6c5d6688a83c",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd41d25-a2c8-413c-940d-79cc27ab8a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               sum_sq    df         F    PR(>F)\n",
      "C(software)                  6.415269   2.0  0.913777  0.404955\n",
      "C(experience)                5.423248   1.0  1.544951  0.217341\n",
      "C(software):C(experience)    0.109416   2.0  0.015585  0.984539\n",
      "Residual                   294.865598  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "data = pd.DataFrame({\n",
    "    'software': np.random.choice(['A', 'B', 'C'], size=90),  # Random assignment to software programs\n",
    "    'experience': np.random.choice(['novice', 'experienced'], size=90),\n",
    "    'time': np.random.normal(loc=10, scale=2, size=90)  # Simulated time data\n",
    "})\n",
    "\n",
    "# Fit two-way ANOVA model\n",
    "model = ols('time ~ C(software) + C(experience) + C(software):C(experience)', data=data).fit()\n",
    "\n",
    "# Print ANOVA table\n",
    "print(sm.stats.anova_lm(model, typ=2))\n",
    "\n",
    "# Interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e2e51d-292e-473c-ad31-ff12e5a96d91",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eeb5b50-57db-4d41-b36a-f9eeb72ebfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test results:\n",
      "t-statistic: -3.0374335758254647\n",
      "p-value: 0.0027074129694694667\n",
      "The p-value is less than 0.05, indicating that there is a significant difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Example data (test scores)\n",
    "control_group = np.random.normal(loc=70, scale=10, size=100)  # Control group (traditional teaching method)\n",
    "experimental_group = np.random.normal(loc=75, scale=10, size=100)  # Experimental group (new teaching method)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "print(\"Two-sample t-test results:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"The p-value is less than 0.05, indicating that there is a significant difference in test scores between the control and experimental groups.\")\n",
    "    # Follow up with post-hoc tests if desired\n",
    "else:\n",
    "    print(\"The p-value is greater than or equal to 0.05, indicating that there is no significant difference in test scores between the control and experimental groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35115f5-e3be-42d1-bc38-c006435ac2b5",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fabda29-15eb-4a8f-819c-22eafb30e7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
