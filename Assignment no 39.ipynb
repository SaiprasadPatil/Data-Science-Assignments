{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fb191a1-498f-47ae-a972-c45f5b49d4b9",
   "metadata": {},
   "source": [
    "Q1. What is data encoding? How is it useful in data science?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4175990-6851-44d6-8c5d-a4b9e500e4f7",
   "metadata": {},
   "source": [
    "### Q1. What is data encoding? How is it useful in data science?\n",
    "\n",
    "**Data Encoding**:\n",
    "\n",
    "Data encoding is the process of converting categorical data into numerical formats that can be used by machine learning algorithms. Categorical data includes non-numeric data such as text labels or categories (e.g., \"red,\" \"blue,\" \"green\" for color, or \"low,\" \"medium,\" \"high\" for risk level).\n",
    "\n",
    "**Types of Data Encoding**:\n",
    "\n",
    "1. **Label Encoding**:\n",
    "   - Converts each category into a unique integer.\n",
    "   - Useful for ordinal data where the order matters (e.g., \"low\" = 0, \"medium\" = 1, \"high\" = 2).\n",
    "\n",
    "2. **One-Hot Encoding**:\n",
    "   - Converts each category into a binary vector.\n",
    "   - Creates a new binary feature for each category, with a value of 1 indicating the presence of the category and 0 otherwise.\n",
    "   - Useful for nominal data where the order does not matter.\n",
    "\n",
    "3. **Binary Encoding**:\n",
    "   - Converts categories to binary code and then splits the binary code into separate columns.\n",
    "   - Reduces dimensionality compared to one-hot encoding.\n",
    "\n",
    "4. **Target Encoding**:\n",
    "   - Replaces a category with the mean (or other statistics) of the target variable for that category.\n",
    "   - Useful for high-cardinality categorical features.\n",
    "\n",
    "5. **Frequency Encoding**:\n",
    "   - Replaces each category with the frequency of its occurrence in the dataset.\n",
    "   - Useful for features where the frequency of occurrence provides significant information.\n",
    "\n",
    "**How Data Encoding is Useful in Data Science**:\n",
    "\n",
    "1. **Compatibility with Machine Learning Algorithms**:\n",
    "   - Most machine learning algorithms require numerical input. Data encoding transforms categorical data into a numerical format that algorithms can process.\n",
    "\n",
    "2. **Handling Categorical Data**:\n",
    "   - Properly encoded data ensures that categorical information is preserved and utilized effectively by machine learning models.\n",
    "\n",
    "3. **Improving Model Performance**:\n",
    "   - Accurate encoding methods can capture the underlying patterns in categorical data, leading to improved model accuracy and performance.\n",
    "\n",
    "4. **Avoiding Bias**:\n",
    "   - Certain encoding methods, like one-hot encoding, prevent introducing ordinal relationships where none exist, thus avoiding potential bias in the model.\n",
    "\n",
    "5. **Feature Engineering**:\n",
    "   - Encoding categorical variables appropriately can help in creating new features or enhancing existing ones, thereby improving the model's predictive power.\n",
    "\n",
    "In summary, data encoding is a crucial step in preprocessing categorical data, making it suitable for use in machine learning models, enhancing the model's ability to learn and make accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f2148-19f1-4e34-b3a1-9b87e2906ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is nominal encoding? Provide an example of how you would use it in a real-world scenario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dba3585-96f4-475d-8d52-83f347b357b0",
   "metadata": {},
   "source": [
    "### Q2. What is nominal encoding? Provide an example of how you would use it in a real-world scenario.\n",
    "\n",
    "**Nominal Encoding**:\n",
    "\n",
    "Nominal encoding is a method of converting categorical data with no intrinsic order (nominal data) into a numerical format. This type of encoding is typically used for categorical variables where the categories are simply different names or labels without any inherent ranking or order.\n",
    "\n",
    "**Types of Nominal Encoding**:\n",
    "\n",
    "1. **One-Hot Encoding**:\n",
    "   - Creates a binary column for each category, with a value of 1 indicating the presence of the category and 0 otherwise.\n",
    "\n",
    "2. **Label Encoding**:\n",
    "   - Assigns a unique integer to each category. However, this method may inadvertently introduce ordinal relationships where none exist, so it is less commonly used for nominal data compared to one-hot encoding.\n",
    "\n",
    "**Example of Nominal Encoding in a Real-World Scenario**:\n",
    "\n",
    "**Scenario**:\n",
    "You are working on a predictive model for an online retail company to recommend products to customers. The dataset includes a feature called \"Product Category,\" which contains nominal data like \"Electronics,\" \"Clothing,\" \"Home Goods,\" and \"Books.\"\n",
    "\n",
    "**Using One-Hot Encoding**:\n",
    "\n",
    "1. **Original Data**:\n",
    "   ```\n",
    "   | CustomerID | ProductCategory |\n",
    "   |------------|-----------------|\n",
    "   | 1          | Electronics     |\n",
    "   | 2          | Clothing        |\n",
    "   | 3          | Home Goods      |\n",
    "   | 4          | Books           |\n",
    "   ```\n",
    "\n",
    "2. **Apply One-Hot Encoding**:\n",
    "   - Create a binary column for each category.\n",
    "   - The resulting dataset will have separate columns for each product category.\n",
    "\n",
    "3. **Encoded Data**:\n",
    "   ```\n",
    "   | CustomerID | Electronics | Clothing | Home Goods | Books |\n",
    "   |------------|-------------|----------|------------|-------|\n",
    "   | 1          | 1           | 0        | 0          | 0     |\n",
    "   | 2          | 0           | 1        | 0          | 0     |\n",
    "   | 3          | 0           | 0        | 1          | 0     |\n",
    "   | 4          | 0           | 0        | 0          | 1     |\n",
    "   ```\n",
    "\n",
    "**Benefits of Using One-Hot Encoding in This Scenario**:\n",
    "\n",
    "1. **Model Compatibility**:\n",
    "   - One-hot encoding converts the categorical \"Product Category\" feature into a format that can be used by most machine learning algorithms, which require numerical input.\n",
    "\n",
    "2. **Preserving Category Information**:\n",
    "   - Each product category is represented as a separate feature, ensuring that the model can learn from the presence or absence of each category without assuming any ordinal relationship.\n",
    "\n",
    "3. **Improving Model Interpretability**:\n",
    "   - The encoded columns clearly indicate the presence of specific product categories, making it easier to interpret the model's predictions and understand the influence of each category on the outcome.\n",
    "\n",
    "By using one-hot encoding for nominal data, you ensure that your machine learning model accurately captures and utilizes the information contained in categorical features, leading to more reliable and interpretable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d1c18-6427-4838-bde5-6fa451c71046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "Q3. In what situations is nominal encoding preferred over one-hot encoding? Provide a practical example.\n",
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c926fdd1-468c-4aa1-a382-50c79e6354fc",
   "metadata": {},
   "source": [
    "### Q3. In what situations is nominal encoding preferred over one-hot encoding? Provide a practical example.\n",
    "\n",
    "**Situations Where Nominal Encoding is Preferred**:\n",
    "\n",
    "1. **High Cardinality**:\n",
    "   - When the categorical feature has a very large number of unique categories, one-hot encoding can lead to a high-dimensional dataset with many binary columns. In such cases, nominal encoding (like Label Encoding or Target Encoding) can be more efficient.\n",
    "\n",
    "2. **Ordinal Information Present**:\n",
    "   - If there is an inherent ordinal relationship in the categories (even if nominal), some nominal encoding methods like Label Encoding might be used to preserve the order, though this is less common for strictly nominal data.\n",
    "\n",
    "3. **Performance Considerations**:\n",
    "   - For models that can handle categorical variables directly or for tasks where feature dimensionality is a concern, nominal encoding might be preferred.\n",
    "\n",
    "4. **Memory and Computational Efficiency**:\n",
    "   - Label Encoding and other nominal encoding methods are more memory-efficient than one-hot encoding because they do not increase the number of columns in the dataset.\n",
    "\n",
    "**Practical Example**:\n",
    "\n",
    "**Scenario**:\n",
    "You are working on a project to predict the type of insurance claim a customer will make based on their profile. One of the features in your dataset is \"Insurance Type,\" which includes categories like \"Health,\" \"Auto,\" \"Home,\" and \"Life.\"\n",
    "\n",
    "**Using Label Encoding**:\n",
    "\n",
    "1. **Original Data**:\n",
    "   ```\n",
    "   | CustomerID | InsuranceType |\n",
    "   |------------|---------------|\n",
    "   | 1          | Health        |\n",
    "   | 2          | Auto          |\n",
    "   | 3          | Home          |\n",
    "   | 4          | Life          |\n",
    "   ```\n",
    "\n",
    "2. **Apply Label Encoding**:\n",
    "   - Assign an integer to each category.\n",
    "\n",
    "3. **Encoded Data**:\n",
    "   ```\n",
    "   | CustomerID | InsuranceType |\n",
    "   |------------|---------------|\n",
    "   | 1          | 0             |\n",
    "   | 2          | 1             |\n",
    "   | 3          | 2             |\n",
    "   | 4          | 3             |\n",
    "   ```\n",
    "\n",
    "**Benefits of Using Label Encoding in This Scenario**:\n",
    "\n",
    "1. **Efficiency**:\n",
    "   - Label Encoding keeps the dataset compact by converting categorical data into a single integer column, which is more efficient than expanding it into multiple binary columns, especially with many categories.\n",
    "\n",
    "2. **Model Compatibility**:\n",
    "   - Some models, such as decision trees or gradient boosting, can handle integer-encoded categorical features without assuming any ordinal relationship. \n",
    "\n",
    "3. **Memory Usage**:\n",
    "   - Label Encoding is memory-efficient because it does not increase the number of columns in the dataset. This can be beneficial for large datasets with many categorical features.\n",
    "\n",
    "4. **Handling High Cardinality**:\n",
    "   - If \"Insurance Type\" had many unique values (e.g., 100+ types), one-hot encoding would create 100+ additional columns. Label Encoding avoids this problem.\n",
    "\n",
    "In this example, Label Encoding is preferred due to its simplicity and efficiency when dealing with high-cardinality categorical features where creating many binary columns would be impractical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c26360-793b-43d6-8c5f-b9635de67f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Suppose you have a dataset containing categorical data with 5 unique values. Which encoding\n",
    "technique would you use to transform this data into a format suitable for machine learning algorithms?\n",
    "Explain why you made this choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf54e1b9-d212-4ba8-8407-d78bd2e9578d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe7ac90-311c-42a0-a01f-e20261c37bad",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1692184799.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Q5. In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Q5. In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns\n",
    "are categorical, and the remaining three columns are numerical. If you were to use nominal encoding to\n",
    "transform the categorical data, how many new columns would be created? Show your calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c43c728-7e47-41c7-92bd-13f88b63d9de",
   "metadata": {},
   "source": [
    "### Q4. Suppose you have a dataset containing categorical data with 5 unique values. Which encoding technique would you use to transform this data into a format suitable for machine learning algorithms? Explain why you made this choice.\n",
    "\n",
    "For a dataset with categorical data containing 5 unique values, **One-Hot Encoding** is generally a suitable choice. Here’s why:\n",
    "\n",
    "**One-Hot Encoding**:\n",
    "\n",
    "1. **Preserves Information**:\n",
    "   - One-hot encoding transforms each categorical value into a separate binary feature, ensuring that the model does not assume any ordinal relationship between the categories. This preserves the information that each category is distinct and equally important.\n",
    "\n",
    "2. **Avoids Misinterpretation**:\n",
    "   - Label Encoding, which assigns unique integers to categories, might inadvertently imply ordinal relationships where none exist. One-hot encoding prevents this issue by representing each category as a binary vector.\n",
    "\n",
    "3. **Model Compatibility**:\n",
    "   - One-hot encoding is compatible with most machine learning algorithms, especially those that require numerical inputs, such as linear models, neural networks, and clustering algorithms.\n",
    "\n",
    "**Example with One-Hot Encoding**:\n",
    "\n",
    "Suppose your categorical data has the following 5 unique values: \"A,\" \"B,\" \"C,\" \"D,\" \"E.\"\n",
    "\n",
    "**Original Data**:\n",
    "```\n",
    "| SampleID | Category |\n",
    "|----------|----------|\n",
    "| 1        | A        |\n",
    "| 2        | B        |\n",
    "| 3        | C        |\n",
    "| 4        | D        |\n",
    "| 5        | E        |\n",
    "```\n",
    "\n",
    "**One-Hot Encoded Data**:\n",
    "```\n",
    "| SampleID | A | B | C | D | E |\n",
    "|----------|---|---|---|---|---|\n",
    "| 1        | 1 | 0 | 0 | 0 | 0 |\n",
    "| 2        | 0 | 1 | 0 | 0 | 0 |\n",
    "| 3        | 0 | 0 | 1 | 0 | 0 |\n",
    "| 4        | 0 | 0 | 0 | 1 | 0 |\n",
    "| 5        | 0 | 0 | 0 | 0 | 1 |\n",
    "```\n",
    "\n",
    "**Reasons for Choosing One-Hot Encoding**:\n",
    "\n",
    "1. **Manageable Dimensionality**:\n",
    "   - With 5 unique values, one-hot encoding results in 5 additional columns, which is manageable and does not lead to a high-dimensional space problem.\n",
    "\n",
    "2. **Model Accuracy**:\n",
    "   - One-hot encoding often leads to better model performance as it prevents the algorithm from making incorrect assumptions about the relationship between categories.\n",
    "\n",
    "3. **Interpretable Results**:\n",
    "   - The resulting binary columns make it easier to interpret the model’s input and understand which category each sample belongs to.\n",
    "\n",
    "**Alternative Considerations**:\n",
    "\n",
    "- **Label Encoding** might be used if the model can handle ordinal relationships or if computational efficiency is a concern. However, for categorical data without an inherent order, one-hot encoding is generally preferred to avoid misleading the model.\n",
    "\n",
    "**Conclusion**:\n",
    "One-hot encoding is typically the best choice for categorical data with 5 unique values, as it accurately represents the data without introducing any unintended ordinal relationships, while maintaining compatibility with most machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924029a4-624f-4d1d-93b8-c16c2936c358",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (944013283.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Q6. You are working with a dataset containing information about different types of animals, including their\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Q6. You are working with a dataset containing information about different types of animals, including their\n",
    "species, habitat, and diet. Which encoding technique would you use to transform the categorical data into\n",
    "a format suitable for machine learning algorithms? Justify your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4e18d-ebcf-4865-8885-3b44f99fbec9",
   "metadata": {},
   "source": [
    "### Q5. In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns are categorical, and the remaining three columns are numerical. If you were to use nominal encoding to transform the categorical data, how many new columns would be created? Show your calculations.\n",
    "\n",
    "**To calculate the number of new columns created by nominal encoding, we need to understand the type of nominal encoding used. Assuming **one-hot encoding**, which is the most common nominal encoding method, the number of new columns created depends on the number of unique values in each categorical column.\n",
    "\n",
    "Let's denote:\n",
    "- \\( C_1 \\) as the number of unique values in the first categorical column.\n",
    "- \\( C_2 \\) as the number of unique values in the second categorical column.\n",
    "\n",
    "**Steps to Calculate New Columns Created:**\n",
    "\n",
    "1. **Determine Unique Values in Each Categorical Column:**\n",
    "\n",
    "   - Suppose the first categorical column has \\( C_1 \\) unique values.\n",
    "   - Suppose the second categorical column has \\( C_2 \\) unique values.\n",
    "\n",
    "2. **Calculate the Number of New Columns Created by One-Hot Encoding:**\n",
    "\n",
    "   - For each categorical column, one-hot encoding creates as many new columns as there are unique values in that column.\n",
    "\n",
    "   - Therefore, the number of new columns created by one-hot encoding for each categorical column will be equal to the number of unique values in that column.\n",
    "\n",
    "   - If the first categorical column has \\( C_1 \\) unique values, it will create \\( C_1 \\) new columns.\n",
    "\n",
    "   - If the second categorical column has \\( C_2 \\) unique values, it will create \\( C_2 \\) new columns.\n",
    "\n",
    "3. **Total Number of New Columns Created:**\n",
    "\n",
    "   - The total number of new columns created will be the sum of the new columns from each categorical column.\n",
    "\n",
    "   \\[\n",
    "   \\text{Total New Columns} = C_1 + C_2\n",
    "   \\]\n",
    "\n",
    "**Example Calculation:**\n",
    "\n",
    "Assume the following for our example:\n",
    "\n",
    "- The first categorical column has 4 unique values.\n",
    "- The second categorical column has 6 unique values.\n",
    "\n",
    "**Applying the Formula:**\n",
    "\n",
    "\\[\n",
    "\\text{Total New Columns} = C_1 + C_2\n",
    "\\]\n",
    "\\[\n",
    "\\text{Total New Columns} = 4 + 6 = 10\n",
    "\\]\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "In this example, using one-hot encoding for the two categorical columns with 4 and 6 unique values, respectively, would create a total of 10 new columns.\n",
    "\n",
    "If you have specific values for \\( C_1 \\) and \\( C_2 \\), you would substitute those numbers into the calculation to find the exact number of new columns created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ad729-8054-469a-9cd6-c3f516e69f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7.You are working on a project that involves predicting customer churn for a telecommunications\n",
    "company. You have a dataset with 5 features, including the customer's gender, age, contract type,\n",
    "monthly charges, and tenure. Which encoding technique(s) would you use to transform the categorical\n",
    "data into numerical data? Provide a step-by-step explanation of how you would implement the encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e7264e-fa8e-4e16-a54f-0ef76ff55123",
   "metadata": {},
   "source": [
    "### Q7. Encoding Categorical Data for Predicting Customer Churn\n",
    "\n",
    "**Project Description:**\n",
    "You are predicting customer churn for a telecommunications company with a dataset including:\n",
    "- Customer’s gender (categorical)\n",
    "- Age (numerical)\n",
    "- Contract type (categorical)\n",
    "- Monthly charges (numerical)\n",
    "- Tenure (numerical)\n",
    "\n",
    "**Steps for Encoding Categorical Data:**\n",
    "\n",
    "1. **Identify Categorical Features:**\n",
    "   - Gender\n",
    "   - Contract type\n",
    "\n",
    "2. **Choose Encoding Techniques:**\n",
    "\n",
    "   - **Gender**: This is a nominal categorical feature with two unique values: \"Male\" and \"Female.\"\n",
    "     - **Encoding Technique**: **Label Encoding** or **One-Hot Encoding**\n",
    "\n",
    "   - **Contract Type**: This is a nominal categorical feature with multiple categories (e.g., \"Month-to-Month,\" \"One Year,\" \"Two Year\").\n",
    "     - **Encoding Technique**: **One-Hot Encoding**\n",
    "\n",
    "**Step-by-Step Implementation:**\n",
    "\n",
    "1. **Preprocessing the Data:**\n",
    "\n",
    "   - **Load and Inspect Data:**\n",
    "     ```python\n",
    "     import pandas as pd\n",
    "\n",
    "     # Load dataset\n",
    "     data = pd.read_csv('customer_churn.csv')\n",
    "\n",
    "     # Inspect the dataset\n",
    "     print(data.head())\n",
    "     ```\n",
    "\n",
    "2. **Encoding Gender:**\n",
    "\n",
    "   - **Label Encoding** (simpler, but assumes ordinal relationship which is not suitable here):\n",
    "     ```python\n",
    "     from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "     # Initialize the LabelEncoder\n",
    "     label_encoder = LabelEncoder()\n",
    "\n",
    "     # Fit and transform the 'Gender' column\n",
    "     data['Gender'] = label_encoder.fit_transform(data['Gender'])\n",
    "\n",
    "     # Print the transformed column\n",
    "     print(data['Gender'].head())\n",
    "     ```\n",
    "\n",
    "   - **One-Hot Encoding** (more appropriate for nominal data):\n",
    "     ```python\n",
    "     # Apply one-hot encoding to 'Gender'\n",
    "     data = pd.get_dummies(data, columns=['Gender'], drop_first=True)\n",
    "\n",
    "     # Print the resulting dataframe\n",
    "     print(data.head())\n",
    "     ```\n",
    "\n",
    "     In this case, `drop_first=True` avoids multicollinearity by removing one of the dummy variables, but it's optional.\n",
    "\n",
    "3. **Encoding Contract Type:**\n",
    "\n",
    "   - **One-Hot Encoding**:\n",
    "     ```python\n",
    "     # Apply one-hot encoding to 'Contract Type'\n",
    "     data = pd.get_dummies(data, columns=['Contract Type'], drop_first=True)\n",
    "\n",
    "     # Print the resulting dataframe\n",
    "     print(data.head())\n",
    "     ```\n",
    "\n",
    "     Here, `drop_first=True` is also used to avoid multicollinearity.\n",
    "\n",
    "4. **Verify Encoding:**\n",
    "   - **Check the transformed dataset:**\n",
    "     ```python\n",
    "     # Display the dataset with encoded features\n",
    "     print(data.head())\n",
    "     ```\n",
    "\n",
    "5. **Integrate Encoded Data with Model Training:**\n",
    "\n",
    "   - Proceed with splitting the dataset into features and target variable and then train your machine learning model.\n",
    "\n",
    "   ```python\n",
    "   # Define features and target variable\n",
    "   X = data.drop('Churn', axis=1)  # Assuming 'Churn' is the target variable\n",
    "   y = data['Churn']\n",
    "\n",
    "   # Train-test split\n",
    "   from sklearn.model_selection import train_test_split\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "   # Train a model (e.g., Logistic Regression)\n",
    "   from sklearn.linear_model import LogisticRegression\n",
    "   model = LogisticRegression()\n",
    "   model.fit(X_train, y_train)\n",
    "\n",
    "   # Evaluate the model\n",
    "   from sklearn.metrics import accuracy_score\n",
    "   y_pred = model.predict(X_test)\n",
    "   print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "   ```\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "- **Gender**: Use **One-Hot Encoding** to avoid introducing ordinal relationships that don't exist.\n",
    "- **Contract Type**: Use **One-Hot Encoding** to convert multiple categories into binary columns.\n",
    "\n",
    "By following these steps, you ensure that categorical data is properly transformed into a format suitable for machine learning algorithms, allowing your model to effectively utilize the encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51e831-c72d-4912-a325-5e9234767a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbab4a99-7456-47d4-b83b-cf92b9ac85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
