{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d7dfae9-f86a-4b0a-a598-fce503721400",
   "metadata": {},
   "source": [
    "Here's a detailed guide for building a decision tree model to predict diabetes based on the provided dataset. The steps include importing and exploring the dataset, preprocessing, training, evaluating, and interpreting the decision tree model.\n",
    "\n",
    "### Q1. Import the Dataset and Examine the Variables\n",
    "\n",
    "**1. Import the Dataset:**\n",
    "\n",
    "Use the `pandas` library to load the dataset and examine the first few rows to understand its structure.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://drive.google.com/uc?id=1Q4J8KS1wm4-_YTuc389enPh6O-eTNcx2'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Display summary statistics\n",
    "print(df.describe())\n",
    "```\n",
    "\n",
    "**2. Understand the Distribution and Relationships:**\n",
    "\n",
    "Use visualization libraries like `matplotlib` and `seaborn` to explore the data.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Histogram of each variable\n",
    "df.hist(bins=20, figsize=(15, 10))\n",
    "plt.show()\n",
    "\n",
    "# Pairplot to understand relationships\n",
    "sns.pairplot(df, hue='Outcome')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Q2. Preprocess the Data\n",
    "\n",
    "**1. Clean Missing Values:**\n",
    "\n",
    "Check for missing values and handle them.\n",
    "\n",
    "```python\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Assuming no missing values; otherwise, handle them accordingly\n",
    "# For instance, you can fill missing values with the mean or median\n",
    "# df.fillna(df.mean(), inplace=True)\n",
    "```\n",
    "\n",
    "**2. Remove Outliers:**\n",
    "\n",
    "Identify and remove outliers if necessary. For simplicity, you might use Z-scores or IQR.\n",
    "\n",
    "```python\n",
    "from scipy import stats\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores = stats.zscore(df.select_dtypes(include=['float64', 'int64']))\n",
    "\n",
    "# Set threshold for identifying outliers\n",
    "threshold = 3\n",
    "df_no_outliers = df[(z_scores < threshold).all(axis=1)]\n",
    "print(f'Original dataset size: {df.shape[0]}')\n",
    "print(f'No outliers dataset size: {df_no_outliers.shape[0]}')\n",
    "```\n",
    "\n",
    "**3. Transform Categorical Variables:**\n",
    "\n",
    "If there were categorical variables, convert them into dummy variables. In this dataset, 'Outcome' is already numeric.\n",
    "\n",
    "```python\n",
    "# No additional transformation needed for categorical variables\n",
    "```\n",
    "\n",
    "### Q3. Split the Dataset into Training and Test Sets\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features and target variable\n",
    "X = df_no_outliers.drop('Outcome', axis=1)\n",
    "y = df_no_outliers['Outcome']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "```\n",
    "\n",
    "### Q4. Train a Decision Tree Model\n",
    "\n",
    "**1. Train the Model:**\n",
    "\n",
    "Use `scikit-learn` to train the decision tree classifier.\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameters to tune\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f'Best parameters: {best_params}')\n",
    "```\n",
    "\n",
    "### Q5. Evaluate the Model\n",
    "\n",
    "**1. Evaluate Performance Metrics:**\n",
    "\n",
    "Use metrics like accuracy, precision, recall, F1 score, confusion matrix, and ROC curve.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix:\\n{cm}')\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC AUC Score: {roc_auc:.2f}')\n",
    "```\n",
    "\n",
    "### Q6. Interpret the Decision Tree\n",
    "\n",
    "**1. Visualize the Tree:**\n",
    "\n",
    "Use `scikit-learn` to visualize the decision tree.\n",
    "\n",
    "```python\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(best_model, feature_names=X.columns, class_names=['Non-Diabetic', 'Diabetic'], filled=True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**2. Interpret the Tree:**\n",
    "\n",
    "Examine the splits, branches, and leaf nodes to understand which features are most important and the thresholds used for splitting. Explain these patterns in terms of the clinical variables.\n",
    "\n",
    "### Q7. Validate the Model\n",
    "\n",
    "**1. Sensitivity Analysis:**\n",
    "\n",
    "Check how changes in the dataset or features affect the model's predictions.\n",
    "\n",
    "```python\n",
    "# Example: Evaluate model performance with different subsets of data or features\n",
    "# Compare performance on different data slices\n",
    "```\n",
    "\n",
    "**2. Scenario Testing:**\n",
    "\n",
    "Apply the model to new or synthetic data to test robustness.\n",
    "\n",
    "```python\n",
    "# Example: Create synthetic data to test model robustness\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "By following these steps, you will be able to build, evaluate, and interpret a decision tree model to predict diabetes in patients using the provided dataset. This process involves understanding the dataset, preprocessing the data, training the model, evaluating performance, and validating the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdaf56c-2997-4220-bdef-d9defd995664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc881a6-608d-4ca8-81b0-7401edd640b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
